name: observability

services:
  # test application
  # testapp:
  #   image: localhost:5000/test-otel
  #   ports:
  #     - "9001:9001"
  #   networks:
  #     - observability_net
  # ðŸ©» Collector
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.102.0
    container_name: otel-coll
    restart: always
    command: ["--config=/etc/otel-collector-config.yaml", "${OTELCOL_ARGS}"]
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - "1777:1777" # pprof extension
      - "8888:8888" # Prometheus metrics exposed by the collector
      - "8889:8889" # Prometheus exporter metrics
      - "13133:13133" # health_check extension
      - "4317:4317" # OTLP gRPC receiver
      - "4318:4318" # OTLP http receiver
      - "55679:55679" # zpages extension
    networks:
      - observability_net
  # Jaeger
  jaeger-all-in-one:
    image: jaegertracing/all-in-one:latest
    container_name: jaeger
    restart: always
    ports:
      - "16686:16686"
      - "14268"
      - "14250"
    networks:
      - observability_net
  # Tempo
  # Tempo runs as user 10001, and docker compose creates the volume as root.
  # As such, we need to chown the volume in order for Tempo to start correctly.
  init:
    image: &tempoImage grafana/tempo:latest
    user: root
    entrypoint:
      - "chown"
      - "10001:10001"
      - "/var/tempo"
    volumes:
      - ./tempo-data:/var/tempo
    networks:
      - observability_net
  tempo:
    image: *tempoImage
    command: ["-config.file=/etc/tempo.yaml"]
    container_name: tempo
    volumes:
      - ./tempo.yaml:/etc/tempo.yaml
      - ./tempo-data:/var/tempo
    ports:
      - "14268:14268" # jaeger ingest
      - "3200:3200" # tempo
      - "9095:9095" # tempo grpc
      # - "4317:4317"  # otlp grpc
      # - "4318:4318"  # otlp http
      - "9411:9411" # zipkin
    depends_on:
      - init
    networks:
      - observability_net
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: always
    volumes:
      - ./prometheus.yaml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    networks:
      - observability_net
  grafana:
    image: grafana/grafana:10.4.0
    container_name: grafana
    ports:
      - "3099:3000"
    volumes:
      - ./grafana-data:/var/lib/grafana
      - ./grafana/dashboards:/var/lib/grafana/dashboards
      - ./grafana/grafana-datasources.yaml:/etc/grafana/provisioning/datasources/datasources.yaml
      - ./grafana/dashboard.yaml:/etc/grafana/provisioning/dashboards/main.yaml
    environment:
      # - GF_SECURITY_ADMIN_PASSWORD=admin
      # - GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH=/var/lib/grafana/dashboards/frontend.json
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_AUTH_DISABLE_LOGIN_FORM=true
      - GF_FEATURE_TOGGLES_ENABLE=traceqlEditor
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit 1",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - observability_net
  loki:
    image: grafana/loki:3.0.0
    container_name: loki
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - ./loki.yaml:/etc/loki/local-config.yaml
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - observability_net

networks:
  observability_net:
    driver: bridge

volumes:
  cache:
    driver: local
